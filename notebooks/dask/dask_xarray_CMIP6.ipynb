{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xarray with Dask Arrays\n",
    "\n",
    "In this notebook we show how to apply xarray operations on Dask DataArray objects.\n",
    "\n",
    "- Open a dataset\n",
    "- Use standard xarray operations\n",
    "- Persist data in memory\n",
    "- Custom workflows and automatic parallelisation\n",
    "\n",
    "The following material uses Coupled Model Intercomparison Project (CMIP6) collections. The CMIP6 terms of use are found [here](https://pcmdi.llnl.gov/CMIP6/TermsOfUse/TermsOfUse6-1.html). \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original Authors: NCI Virtual Research Environment Team\n",
    "- Keywords: CMIP6, xarray, dask\n",
    "- CreationDate: 2020-May\n",
    "---\n",
    "-  Adapted to DKRZ jupyterhub and data pool: S. Kindermann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import dask\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Dask Client for Dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the correct status link for dashboard\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "dask.config.config.get('distributed').get('dashboard').update({'link':'{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(n_workers=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the Dask Client will provide a dashboard which is useful to gain insight into the computation. The link to the dashboard will become visible when you create the Client. We recommend having the Client open on one side of your screen and your notebook open on the other side, which will be useful for learning purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a dataset\n",
    "\n",
    "Xarray is an open source project and Python package that extends the labeled data functionality of Pandas to N-dimensional array-like datasets. It shares a similar API to NumPy and Pandas and supports both Dask and NumPy arrays under the hood. \n",
    "\n",
    "By specifying the chunk shape, xarray will automatically create Dask arrays for each data variable in the `Dataset`. In xarray, `Datasets` are dict-like containers of labelled arrays, analogous to the `pandas.DataFrame`. Note that we're taking advantage of xarray's dimension labels when specifying chunk shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /pool/data/CMIP6/data/CMIP/CSIRO-ARCCSS/ACCESS-CM2/historical/r1i1p1f1/6hrPlevPt/psl/gn/v20191108/*.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On DKRZ system\n",
    "filename = '/pool/data/CMIP6/data/CMIP/CSIRO-ARCCSS/ACCESS-CM2/historical/r1i1p1f1/6hrPlevPt/psl/gn/v20191108/*.nc'\n",
    "#filename = '/pool/data/CMIP6/data/CMIP/CSIRO-ARCCSS/ACCESS-CM2/historical/r1i1p1f1/6hrLevPt/psl/v20191108/gn/latest/*.nc'\n",
    "ds = xr.open_mfdataset(filename,combine='nested', concat_dim='time',chunks={'lat': 144, 'lon': 92, 'time': -1})\n",
    "ds = ds.sel(time=slice('1950','1951'))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly inspecting the `Dataset` above, we'll note that this `Dataset` has four _dimensions_ akin to axes in NumPy (`bnds`, `lat`, `lon`, and `time`), three _coordinate variables_ akin to `pandas.Index` objects (also named `lat`, `lon`, and `time`), and one data variable (`psl`) as well as two data varibles defining the lat and lon cell bounds (`lat_bnds`, `lon_bnds`). Xarray also holds Dataset specific metadata as _attributes_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds['psl']\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data variable in xarray is called a `DataArray`. These are the fundemental labelled array object in xarray. Much like the `Dataset`, `DataArrays` also have _dimensions_ and _coordinates_ that support many of its label-based opperations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the underlying array of data is done via the `data` property. Here we can see that the Dask array is backed by a NumPy array of the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Standard Xarray Operations\n",
    "\n",
    "In almost all cases, operations using xarray objects are identical regardless of whether the underlying data is stored as a Dask array or a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da2 = da.groupby('time.month').mean('time')\n",
    "da3 = da.groupby('time.month') - da2\n",
    "da3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da3.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `.compute()` or `.load()` when you want your result as an `xarray.DataArray` with data stored as NumPy arrays.\n",
    "\n",
    "If you started `Client()` above then you may want to watch the status page during computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_da = da3.load()\n",
    "type(computed_da.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "computed_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist data in memory\n",
    "\n",
    "If you have the available RAM for your dataset then you can persist data in memory.  \n",
    "\n",
    "This allows future computations to be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Operations\n",
    "\n",
    "We want datetime index time-series operations to work efficiently. Here we demo the use of xarray's resample method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.resample(time='1D').mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a rolling window of 30 timesteps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_smooth = da.rolling(time=30).mean().persist()\n",
    "da_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since xarray stores each of its coordinate variables in memory, slicing by label is trivial and entirely lazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time da.sel(time='1950-01-01T18:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time da.sel(time='1950-01-01T18:00:00').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom workflows and automatic parallelisation\n",
    "Almost all of xarray’s built-in operations work on Dask arrays. If you want to use a function that isn’t wrapped by xarray, one option is to extract Dask arrays from xarray objects (`.data`) and use Dask directly.\n",
    "\n",
    "Another option is to use xarray’s `apply_ufunc()` function, which can automate embarrassingly parallel “map” type operations where a function written for processing NumPy arrays should be repeatedly applied to xarray objects containing Dask arrays. It works similarly to `dask.array.map_blocks()` and `dask.array.atop()`, but without requiring an intermediate layer of abstraction.\n",
    "\n",
    "Here we show an example using NumPy operations and a fast function from `bottleneck`, which we use to calculate Spearman’s rank-correlation coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import bottleneck\n",
    "\n",
    "def covariance_gufunc(x, y):\n",
    "    return ((x - x.mean(axis=-1, keepdims=True))\n",
    "            * (y - y.mean(axis=-1, keepdims=True))).mean(axis=-1)\n",
    "\n",
    "def pearson_correlation_gufunc(x, y):\n",
    "    return covariance_gufunc(x, y) / (x.std(axis=-1) * y.std(axis=-1))\n",
    "\n",
    "def spearman_correlation_gufunc(x, y):\n",
    "    x_ranks = bottleneck.rankdata(x, axis=-1)\n",
    "    y_ranks = bottleneck.rankdata(y, axis=-1)\n",
    "    return pearson_correlation_gufunc(x_ranks, y_ranks)\n",
    "\n",
    "def spearman_correlation(x, y, dim):\n",
    "    return xr.apply_ufunc(\n",
    "        spearman_correlation_gufunc, x, y,\n",
    "        input_core_dims=[[dim], [dim]],\n",
    "        dask='parallelized',\n",
    "        output_dtypes=[float])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples above, we were working with some atmospheric pressure data. For this example, we'll calculate the spearman correlation using the raw pressure data with the smoothed version that we also created (`da_smooth`). For this, we'll also have to rechunk the data ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = spearman_correlation(da.chunk({'time': -1}),\n",
    "                            da_smooth.chunk({'time': -1}),\n",
    "                            'time')\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this data and add coastlines for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "f, axs = plt.subplots(1,1,figsize=(12,8))\n",
    "p = plt.subplot(111, projection=ccrs.PlateCarree())\n",
    "p = corr.plot(transform=ccrs.PlateCarree())\n",
    "p.axes.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the client\n",
    "\n",
    "Before moving on to the next exercise, make sure to close your client or stop this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "https://examples.dask.org/xarray.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

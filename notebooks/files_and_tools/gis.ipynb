{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare modeling data for GIS analyses\n",
    "The most common way to work with climate modeling data sets is storing them in NetCDF or GRIB format and processing them using Xarray. Raster data sets used in GIS applications are usually stored in raster formats such as GeoTIFF, BIL, or IMG and being processed mainly with the help of GDAL-based python libraries. While modeling data sets are normally georeferenced using grids explicitly described by coordinates and conforming to e.g., CF sandard, geographic reference of GIS data sets is described by a coordinate reference system (CRS). This diferences imply some steps that need to be undertaken in order to convert data sets from one format to another.\n",
    "\n",
    "In this notebook we create an aggregated map of pre-industrial Vertically Averaged Sea Water Potential Temperature (thetaot) from CMIP6 and save it as GeoTIFF.\n",
    "\n",
    "First, we import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import intake, requests, aiohttp\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cf_xarray as cfxr\n",
    "import xesmf as xe\n",
    "# clisops doc: https://clisops.readthedocs.io/en/latest/\n",
    "from clisops.utils import dataset_utils\n",
    "import clisops.core as clore\n",
    "\n",
    "# Rioxarray is an experimental interface between Xarray and Rasterio libraries\n",
    "# made for loading GDAL-readable rasters as xarray datasets and saving xarrays as raster files.\n",
    "import rioxarray\n",
    "#print(\"Using roocs/clisops in version %s\" % cl.__version__)\n",
    "print(\"Using xESMF in version %s\" % xe.__version__)\n",
    "\n",
    "xr.set_options(display_style = \"html\");\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find and load the data set\n",
    "Then we find the data set we need in the DKRZ open catalogue and print its metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to master catalog on the DKRZ server\n",
    "#dkrz_catalog=intake.open_catalog([\"https://dkrz.de/s/intake\"])\n",
    "#\n",
    "#only for the web page we need to take the original link:\n",
    "dkrz_catalog=intake.open_catalog([\"https://gitlab.dkrz.de/data-infrastructure-services/intake-esm/-/raw/master/esm-collections/cloud-access/dkrz_catalog.yaml\"])\n",
    "# Print DKRZ open catalogues\n",
    "list(dkrz_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get [thetaot](https://clipc-services.ceda.ac.uk/dreq/u/b5bc9b1fa92a35cec5989eeac3d77d1a.html) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the catalog with the intake package and name it \"col\" as short for \"collection\"\n",
    "\n",
    "cols=dkrz_catalog._entries[\"dkrz_cmip6_disk\"]._open_args[\"csv_kwargs\"][\"usecols\"]+[\"opendap_url\"]\n",
    "col=dkrz_catalog.dkrz_cmip6_disk(csv_kwargs=dict(usecols=cols))\n",
    "cat = col.search(variable_id = \"thetaot\",\n",
    "                 experiment_id = \"historical\",\n",
    "                time_range = \"185001-194912\",\n",
    "                member_id = \"r1i1p1f3\"\n",
    "                )\n",
    "cat.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = xr.open_dataset(cat.df.uri.values[0], chunks = {\"time\": 6})\n",
    "dset[\"thetaot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, coordinates are stored as arrays of grid cell indices, which is not a common format in the GIS community.\n",
    "\n",
    "\n",
    "## 2. Calculate pre-industrial mean\n",
    "We make a subset limiting the data set to pre-industrial era, calculate the mean values per grid cell, and plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset[\"time\"] = dset[\"time\"].dt.strftime(\"%Y%m%d\")\n",
    "pre_industrial = dset[\"thetaot\"].sel(time = slice(\"1850\", \"1880\"))\n",
    "pre_industrial_mean = pre_industrial.mean(dim = \"time\", keep_attrs = True).to_dataset()\n",
    "pre_industrial_mean.thetaot.plot(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plotted the data along the index dimensions. However, we would like to plot the data with respect to the latitude and longitude coordinates. These are two dimensional coordinate variables for data on a curvilinear grid, and need to be referenced in the plot command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize = [30, 13])\n",
    "\n",
    "# Set the projection to use for plotting\n",
    "ax = plt.subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "# Shift longitude interval from [-180,180] to [0,360] to avoid \n",
    "#  shading issues with some cartopy/matplotlib versions\n",
    "pre_industrial_mean[\"longitude\"] = xr.where(pre_industrial_mean[\"longitude\"]<0.,\n",
    "                                            pre_industrial_mean[\"longitude\"]+360.,\n",
    "                                            pre_industrial_mean[\"longitude\"],\n",
    "                                            keep_attrs=True)\n",
    "# alternatively use clisops to shift the longitude interval:\n",
    "#pre_industrial_mean = dataset_utils.cf_convert_between_lon_frames(ds_in=pre_industrial_mean,\n",
    "#                                                                  lon_interval=(0, 360))[0]\n",
    "\n",
    "# Pass ax as an argument when plotting. Here we assume data is in the same coordinate reference \n",
    "# system than the projection chosen for plotting isel allows to select by indices instead\n",
    "# of the time values\n",
    "pre_industrial_mean.thetaot.plot.pcolormesh(ax=ax, x=\"longitude\", y=\"latitude\", \n",
    "                                           shading=\"auto\", cmap=\"coolwarm\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "def plot_curv_grid(ds, var = \"tos\"):    \n",
    "        lat = cfxr.accessor._get_with_standard_name(ds, \"latitude\")[0]\n",
    "        lon = cfxr.accessor._get_with_standard_name(ds, \"longitude\")[0]        \n",
    "        if any([i == None for i in [lat, lon]]): \n",
    "            print(ds.attrs[\"source_id\"], \": Cannot identify latitude/longitude.\")\n",
    "            return\n",
    "        plt.figure(figsize = (16, 9), dpi=120)\n",
    "        plt.scatter(x = ds[lon], y = ds[lat], s = 0.01)\n",
    "        # x, y = np.meshgrid(ds[lon], ds[lat])\n",
    "        # plt.scatter(x = x, y = y, s = 0.01)\n",
    "        try:\n",
    "            plt.title(\"\\n\".join(\n",
    "                textwrap.wrap(\n",
    "                    ds.attrs[\"source_id\"] + \"(\" \n",
    "                    + ds.attrs[\"source\"].split(\"ocean:\")[-1].split(\"\\n\")[0] + \")\", \n",
    "                    120)\n",
    "            ))\n",
    "        except (KeyError, IndexError):\n",
    "            plt.title(ds.attrs[\"source_id\"])  \n",
    "plot_curv_grid(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reformat the grid and regrid the data set.\n",
    "As we mentioned before, the coordinates need to be re-defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a global 1deg target grid\n",
    "\n",
    "# With clisops\n",
    "#ds_out = clore.Grid(grid_instructor=(1., )).ds\n",
    "\n",
    "# Without clisops\n",
    "ds_out = xe.util.grid_global(1., 1., cf=True)\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we regrid the data set to a normal 1-degree global grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of problems, activate ESMF verbose mode\n",
    "import ESMF\n",
    "ESMF.Manager(debug = True)\n",
    "\n",
    "# Regridding methods\n",
    "#method_list = [\"bilinear\", \"nearest_s2d\", \"patch\", \"conservative\"]\n",
    "\n",
    "# Function to generate the weights\n",
    "#   If grids have problems of degenerated cells near the poles there is the ignore_degenerate option\n",
    "def regrid(ds_in, ds_out, method, periodic, unmapped_to_nan = True, ignore_degenerate = None):\n",
    "    \"\"\"Convenience function for calculating regridding weights\"\"\"\n",
    "    return xe.Regridder(ds_in, ds_out, method, periodic = periodic, \n",
    "                        ignore_degenerate = ignore_degenerate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time regridder = regrid(pre_industrial_mean, \\\n",
    "                         ds_out, \\\n",
    "                         method=\"bilinear\", \\\n",
    "                         periodic=True, \\\n",
    "                         unmapped_to_nan=True, \\\n",
    "                         ignore_degenerate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridded_ds = regridder(pre_industrial_mean, keep_attrs=True)\n",
    "regridded_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize = [30, 13])\n",
    "\n",
    "# Set the projection to use for plotting\n",
    "ax = plt.subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "# Pass ax as an argument when plotting. Here we assume data is in the\n",
    "# same coordinate reference system than the projection chosen for plotting\n",
    "# isel allows to select by indices instead of the time values\n",
    "regridded_ds.thetaot.plot.pcolormesh(ax=ax, cmap=\"coolwarm\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, data on a regular latitude longitude grid is plotted properly\n",
    "without further specifications.\n",
    "\n",
    "## 4. Write a CRS and save the data set as a GeoTIFF\n",
    "It is pretty straitforward to write a CRS to an xarray with rioxarray. Here we used the World Geodetic System 1984 CRS which is quite common and used by default, for example in QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You might need to rename the axes before\n",
    "transformed = regridded_ds.rename({\"lon\":\"x\", \"lat\":\"y\"})\n",
    "\n",
    "transformed = transformed.rio.write_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, saving our dataset as a GeoTIFF is as easy as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed.rio.to_raster(\"gis_ready.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and plot the GeoTIFF\n",
    "\n",
    "Now we can open and perform any kind of GIS processing with this dataset. For the purpose of this workshop we will simply visualize it with contour lines using pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "\n",
    "fp = r'gis_ready.tif'\n",
    "img = rasterio.open(fp)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(13, 30))\n",
    "show((img, 1), interpolation='none', ax=ax)\n",
    "plt.gca().invert_yaxis()\n",
    "show((img, 1), contour=True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sschool",
   "language": "python",
   "name": "sschool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
